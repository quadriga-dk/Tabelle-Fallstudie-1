

@misc{deutsche_forschungsgemeinschaft_guidelines_2022,
  author       = {Deutsche Forschungsgemeinschaft},
  title        = {Guidelines for Safeguarding Good Research
                   Practice. Code of Conduct
                  },
  month        = apr,
  year         = 2022,
  publisher    = {Deutsche Forschungsgemeinschaft},
  doi          = {10.5281/zenodo.6472827},
  url          = {https://doi.org/10.5281/zenodo.6472827},
}

@techreport{spiecker_ecodm_2022,
	title = {{EcoDM} - Ökosystem {Datenmanagement}: {Analysen} - {Empfehlungen} - {FAIRifizierung}},
	shorttitle = {{EcoDM} - Ökosystem {Datenmanagement}},
	url = {https://zenodo.org/records/6256398},
	abstract = {Mit dem BMBF geförderten Verbundprojekt EcoDM (Förderkennzeichen 16DWWQP) wurde erforscht, welche Herausforderungen, Chancen und Hindernisse sich im Bereich des rasanten digitalen Datenwachstums ergeben und wie Rahmenbedingungen aussehen könnten, Daten systematisch und FAIR (Findable, Accessible, Interoperable, Reusable) nutzen und teilen zu können. Einen zentralen Teil der Untersuchung bildeten neben Landscape- und Gap-Analysen Leitfaden-gestützte Interviews mit Expert*innen aus den Bereichen Wissenschaft, Wirtschaft, Public Sector und Qualifizierung. Basierend auf den Projektergebnissen wurden Empfehlungen zur Förderung des Teilens und Nachnutzens von Daten entwickelt. Der vorliegende Report veröffentlicht die gesammelten Untersuchungsergebnisse gemeinsam mit den 31 abgeleiteten bereichsübergreifenden Empfehlungen und die Diskussion dieser Empfehlungen im Rahmen der RDA Deutschland Tagung 2022.},
	language = {deu},
	urldate = {2024-06-06},
	institution = {Zenodo},
	author = {Spiecker, Claus and Richter, Janina and Walter, Paul and Chlastak, Maria and Burkart, Christine and Schneidenbach, Esther and Messerschmidt, Reinhard and Endres, Kirsten and Djeffal, Christian and Nürnberger, Eva},
	month = apr,
	year = {2022},
	doi = {10.5281/zenodo.6256398},
	file = {Full Text PDF:C\:\\Users\\ant87282\\Zotero\\storage\\AU9GK5PL\\Spiecker et al. - 2022 - EcoDM - Ökosystem Datenmanagement Analysen - Empf.pdf:application/pdf},
}

@misc{hollander_parthenos_2019,
	title = {{PARTHENOS} {Leitfaden} zur "{FAIRifizierung}" des {Datenmanagements} und der {Ermöglichung} der {Nachnutzung} von {Daten}},
	url = {https://zenodo.org/records/3363078},
	author = {Hollander, Helli},
	year = {2019},
}

@misc{go_fair_fair_nodate,
	title = {{FAIR} {Principles}},
	url = {https://www.go-fair.org/fair-principles/},
	author = {{GO FAIR}},
}

@misc{wilkinson_fair-prinzipien_2016,
  author       = {Wilkinson, Mark D. and
                  Dumontier, Michel and
                  Aalbersberg, IJsbrand Jan and
                  Appleton, Gabrielle and
                  Axton, Myles and
                  Baak, Arie and
                  Blomberg, Niklas and
                  Boiten, Jan-Willem and
                  da Silva Santos, Luiz Bonino and
                  Bourne, Philip E. and
                  Bouwman, Jildau and
                  Brookes, Anthony J. and
                  Clark, Tim and
                  Crosas, Mercè and
                  Dillo, Ingrid and
                  Dumon, Olivier and
                  Edmunds, Scott and
                  Evelo, Chris T. and
                  Finkers, Richard and
                  Gonzalez-Beltran, Alejandra and
                  Gray, Alasdair J.G. and
                  Groth, Paul and
                  Goble, Carole and
                  Grethe, Jeffrey S. and
                  Heringa, Jaap and
                  't Hoen, Peter A.C. and
                  Hooft, Rob and
                  Kuhn, Tobias and
                  Kok, Ruben and
                  Kok, Joost and
                  Lusher, Scott J. and
                  Martone, Maryann E. and
                  Mons, Albert and
                  Packer, Abel L. and
                  Persson, Bengt and
                  Rocca-Serra, Philippe and
                  Roos, Marco and
                  van Schaik, Rene and
                  Sansone, Susanna-Assunta and
                  Schultes, Erik and
                  Sengstag, Thierry and
                  Slater, Ted and
                  Strawn, George and
                  Swertz, Morris A. and
                  Thompson, Mark and
                  van der Lei, Johan and
                  van Mulligen, Erik and
                  Velterop, Jan and
                  Waagmeester, Andra and
                  Wittenburg, Peter and
                  Wolstencroft, Katherine and
                  Zhao, Jun and
                  Mons, Barend},
  title        = {Die FAIR-Prinzipien für das wissenschaftliche
                   Datenmanagement und Data Stewardship
                  },
  month        = mar,
  year         = 2016,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.6247015},
  url          = {https://doi.org/10.5281/zenodo.6247015},
}

@techreport{force11_joint_2014,
	title = {Joint {Declaration} of {Data} {Citation} {Principles}},
	url = {https://doi.org/10.25490/a97f-egyk},
	institution = {Data Citation Synthesis Group},
	author = {{FORCE11}},
	year = {2014},
}

@misc{noauthor_open_2023,
	title = {Open {Data}, {Open} {Access} und {Nachnutzung}},
	url = {https://forschungsdaten.info/themen/finden-und-nachnutzen/open-data-open-access-und-nachnutzung/},
	month = may,
	year = {2023},
}

@article{behkamal_metrics-driven_2014,
	title = {A metrics-driven approach for quality assessment of linked open data},
	volume = {9},
	issn = {0718-1876},
	doi = {10.4067/S0718-18762014000200006},
	abstract = {The main objective of the Web of Data paradigm is to crystallize knowledge through the interlinking of already existing but dispersed data. The usefulness of the developed knowledge depends strongly on the quality of the published data. Researchers have observed many deficiencies with regard to the quality of Linked Open Data. The first step towards improving the quality of data released as a part of the Linked Open Data Cloud is to develop tools for measuring the quality of such data. To this end, the main objective of this paper is to propose and validate a set of metrics for evaluating the inherent quality characteristics of a dataset before it is released to the Linked Open Data Cloud. These inherent characteristics are semantic accuracy, syntactic accuracy, uniqueness, completeness and consistency. We follow the Goal-Question-Metric approach to propose various metrics for each of these five quality characteristics. We provide both theoretical validation and empirical observation of the behavior of the proposed metrics in this paper. The proposed set of metrics establishes a starting point for a systematic inherent quality analysis of open datasets. © 2014 Universidad de Talca - Chile.},
	language = {English},
	number = {2},
	journal = {Journal of Theoretical and Applied Electronic Commerce Research},
	author = {Behkamal, B. and Kahani, M. and Bagheri, E. and Jeremic, Z.},
	year = {2014},
	keywords = {Linked Data, Datenqualität, Open Data},
	pages = {64--79},
	annote = {Cited By :48},
	file = {Full Text:C\:\\Users\\ant87282\\Zotero\\storage\\DEHKQJ83\\Behkamal et al. - 2014 - A metrics-driven approach for quality assessment o.pdf:application/pdf;Snapshot:C\:\\Users\\ant87282\\Zotero\\storage\\CBQHIFWT\\display.html:text/html},
}

@book{bruns_leitfaden_2019,
	title = {Leitfaden für qualitativ hochwertige {Daten} und {Metadaten}},
	shorttitle = {{NQDM}-{Leitfaden}},
	url = {https://nqdm-projekt.de/de/downloads/leitfaden},
	abstract = {Dieser Leitfaden bietet praktische Hilfestellungen und Empfehlungen zur Erreichung einer hohen Datenund Metadatenqualität. Die enthaltenen Empfehlungen können grundsätzlich auf jegliche Art von Daten
angewendet werden, unabhängig von Zugänglichkeit, Herkunft und dem sektoralen Bezug. Besonders ist
der Leitfaden für Datenbereitsteller aus der öffentlichen Verwaltung empfehlenswert, die ihre Daten als
Open Data veröffentlichen.
Im Leitfaden werden unterschiedliche Qualitätsdimensionen, Datenstrukturtypen und Bewertungsschemata
für die Qualität von Daten und Metadaten aufgezeigt. Gängige maschinenlesbare und offene Daten- und
Schnittstellenformate werden vorgestellt und anhand anschaulicher Beispiele wird aufgezeigt, wie eine
hohe Datenqualität erreicht werden kann.
Der Leitfaden wurde im Rahmen des Projektes NQDM – Normentwurf für qualitativ hochwertige Daten und
Metadaten – von Fraunhofer FOKUS im Zeitraum von September 2017 bis August 2019 erstellt.
Weiterführende Informationen zu dem Projekt können unter https://www.nqdm-projekt.de/ eingesehen
werden.},
	language = {Deutsch},
	publisher = {Fraunhofer-Institut für Offene Kommunikationssysteme FOKUS},
	author = {Bruns, Lina and Dittwald, Benjamin and Meiners, Fritz},
	year = {2019},
	keywords = {Datenqualität, Open Data},
	file = {_.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\ZQAYCKSW\\_.pdf:application/pdf},
}

@article{neumaier_automated_2016,
	title = {Automated {Quality} {Assessment} of {Metadata} across {Open} {Data} {Portals}},
	volume = {8},
	issn = {1936-1955},
	url = {https://dl.acm.org/doi/10.1145/2964909},
	doi = {10.1145/2964909},
	abstract = {The Open Data movement has become a driver for publicly available data on the Web. More and more data—from governments and public institutions but also from the private sector—are made available online and are mainly published in so-called Open Data portals. However, with the increasing number of published resources, there is a number of concerns with regards to the quality of the data sources and the corresponding metadata, which compromise the searchability, discoverability, and usability of resources. In order to get a more complete picture of the severity of these issues, the present work aims at developing a generic metadata quality assessment framework for various Open Data portals: We treat data portals independently from the portal software frameworks by mapping the specific metadata of three widely used portal software frameworks (CKAN, Socrata, OpenDataSoft) to the standardized Data Catalog Vocabulary metadata schema. We subsequently define several quality metrics, which can be evaluated automatically and in an efficient manner. Finally, we report findings based on monitoring a set of over 260 Open Data portals with 1.1M datasets. This includes the discussion of general quality issues, for example, the retrievability of data, and the analysis of our specific quality metrics.},
	number = {1},
	urldate = {2024-04-23},
	journal = {Journal of Data and Information Quality},
	author = {Neumaier, Sebastian and Umbrich, Jürgen and Polleres, Axel},
	year = {2016},
	pages = {2:1--2:29},
	file = {Full Text PDF:C\:\\Users\\ant87282\\Zotero\\storage\\A7M4FUT8\\Neumaier et al. - 2016 - Automated Quality Assessment of Metadata across Op.pdf:application/pdf},
}

@article{vetro_open_2016,
	title = {Open data quality measurement framework: {Definition} and application to {Open} {Government} {Data}},
	volume = {33},
	issn = {0740-624X},
	shorttitle = {Open data quality measurement framework},
	url = {https://www.sciencedirect.com/science/article/pii/S0740624X16300132},
	doi = {10.1016/j.giq.2016.02.001},
	abstract = {The diffusion of Open Government Data (OGD) in recent years kept a very fast pace. However, evidence from practitioners shows that disclosing data without proper quality control may jeopardize dataset reuse and negatively affect civic participation. Current approaches to the problem in literature lack a comprehensive theoretical framework. Moreover, most of the evaluations concentrate on open data platforms, rather than on datasets. In this work, we address these two limitations and set up a framework of indicators to measure the quality of Open Government Data on a series of data quality dimensions at most granular level of measurement. We validated the evaluation framework by applying it to compare two cases of Italian OGD datasets: an internationally recognized good example of OGD, with centralized disclosure and extensive data quality controls, and samples of OGD from decentralized data disclosure (municipality level), with no possibility of extensive quality controls as in the former case, hence with supposed lower quality. Starting from measurements based on the quality framework, we were able to verify the difference in quality: the measures showed a few common acquired good practices and weaknesses, and a set of discriminating factors that pertain to the type of datasets and the overall approach. On the basis of this evaluation, we also provided technical and policy guidelines to overcome the weaknesses observed in the decentralized release policy, addressing specific quality aspects.},
	number = {2},
	urldate = {2024-04-22},
	journal = {Government Information Quarterly},
	author = {Vetrò, Antonio and Canova, Lorenzo and Torchiano, Marco and Minotas, Camilo Orozco and Iemma, Raimondo and Morando, Federico},
	month = apr,
	year = {2016},
	keywords = {Datenqualität, Open Data},
	pages = {325--337},
	file = {Full Text:C\:\\Users\\ant87282\\Zotero\\storage\\95AYPPPF\\Vetrò et al. - 2016 - Open data quality measurement framework Definitio.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ant87282\\Zotero\\storage\\3ICYTV2A\\S0740624X16300132.html:text/html},
}

@article{pipino_data_2002,
	title = {Data {Quality} {Assessment}},
	volume = {45},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/505248.506010},
	doi = {10.1145/505248.506010},
	abstract = {How good is a company's data quality? Answering this question requires usable data quality metrics. Currently, most data quality measures are developed on an ad hoc basis to solve specific problems [6, 8], and fundamental principles necessary for developing usable metrics in practice are lacking. In this article, we describe principles that can help organizations develop usable data quality metrics.},
	language = {en},
	number = {4},
	urldate = {2024-04-22},
	journal = {Communications of the ACM},
	author = {Pipino, Leo L. and Lee, Yang W. and Wang, Richard Y.},
	month = apr,
	year = {2002},
	keywords = {Datenqualität, Open Data},
	pages = {211--218},
	file = {Full Text PDF:C\:\\Users\\ant87282\\Zotero\\storage\\ZQIL2LVE\\Pipino et al. - 2002 - Data quality assessment.pdf:application/pdf},
}

@inproceedings{vaddepalli_taxonomy_2023,
	address = {Singapore},
	title = {Taxonomy of {Data} {Quality} {Metrics} in {Digital} {Citizen} {Science}},
	isbn = {978-981-19766-0-5},
	doi = {10.1007/978-981-19-7660-5_34},
	abstract = {},
	language = {en},
	booktitle = {Intelligent {Sustainable} {Systems}},
	publisher = {Springer Nature},
	author = {Vaddepalli, Krishna and Palacin, Victoria and Porras, Jari and Happonen, Ari},
	editor = {Nagar, Atulya K. and Singh Jat, Dharm and Mishra, Durgesh Kumar and Joshi, Amit},
	year = {2023},
	keywords = {Datenqualität, Open Data},
	pages = {391--410},
	file = {Full Text PDF:C\:\\Users\\ant87282\\Zotero\\storage\\5N7VHBZU\\Vaddepalli et al. - 2023 - Taxonomy of Data Quality Metrics in Digital Citize.pdf:application/pdf},
}

@misc{bruns_checkliste_2019,
	title = {Checkliste zur {Steigerung} der {Datenqualität} von {CSV}-{Dateien}},
	shorttitle = {{NQDM}-{Checkliste}-{CSV}},
	url = {https://nqdm-projekt.de/de/downloads/leitfaden},
	abstract = {Die Checkliste hilft dabei, die Qualität von CSV-Dateien zu überprüfen und auf einfache Weise mögliche Qualitätsprobleme zu identifizieren. Die Checkliste basiert auf dem NQDM-Leitfaden zur Steigerung der Qualität von Daten und Metadaten.
Dieser Leitfaden wurde im Rahmen des Projektes NQDM – Normentwurf für qualitativ hochwertige Daten und Metadaten – von Fraunhofer FOKUS im Zeitraum von September 2017 bis August 2019 erstellt. Weiterführende Informationen zu dem Projekt können unter https://www.nqdm-projekt.de/ eingesehen werden.},
	language = {Deutsch},
	publisher = {Fraunhofer-Institut für Offene Kommunikationssysteme FOKUS},
	author = {Bruns, Lina and Dittwald, Benjamin and Meiners, Fritz},
	year = {2019},
	keywords = {Datenqualität, Open Data},
}

@misc{noauthor_verhaltenskodex_2018,
	title = {Verhaltenskodex für europäische {Statistiken}},
	url = {https://ec.europa.eu/eurostat/documents/4031688/9394019/KS-02-18-142-DE-N.pdf},
	publisher = {Amt für Veröffentlichungen der Europäischen Union},
	year = {2018},
	keywords = {Datenqualität, Statistikdaten},
	file = {2018 - Verhaltenskodex für europäische Statistiken.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\ZW88DNDT\\2018 - Verhaltenskodex für europäische Statistiken.pdf:application/pdf},
}

@misc{noauthor_fundamental_2014,
	title = {Fundamental {Principles} of {National} {Official} {Statistics}},
	url = {https://unstats.un.org/unsd/dnss/gp/fundprinciples.aspx},
	publisher = {United Nations Statistics Divison},
	year = {2014},
	keywords = {Datenqualität, Statistikdaten},
	file = {2014 - Fundamental Principles of National Official Statis.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\YLPHII2Q\\2014 - Fundamental Principles of National Official Statis.pdf:application/pdf},
}

@incollection{gangemi_assessing_2018,
	address = {Cham},
	title = {Assessing {FAIR} {Data} {Principles} {Against} the 5-{Star} {Open} {Data} {Principles}},
	volume = {11155},
	isbn = {978-3-319-98191-8 978-3-319-98192-5},
	url = {https://link.springer.com/10.1007/978-3-319-98192-5_60},
	abstract = {Access to biomedical data is increasingly important to enable data driven science in the research community. The Linked Open Data (LOD) principles (by Tim Berner-Lee) have been suggested to judge the quality of data by its accessibility (open data access), by its format and structures, and by its interoperability with other data sources. The objective is to use interoperable data sources across the Web with ease. The FAIR (ﬁndable, accessible, interoperable, reusable) data principles have been introduced for similar reasons with a stronger emphasis on achieving reusability. In this manuscript we assess the FAIR principles against the LOD principles to determine, to which degree, the FAIR principles reuse LOD principles, and to which degree they extend the LOD principles. This assessment helps to clarify the relationship between both schemes and gives a better understanding, what extension FAIR represents in comparison to LOD.},
	language = {en},
	urldate = {2024-06-01},
	booktitle = {The {Semantic} {Web}: {ESWC} 2018 {Satellite} {Events}},
	publisher = {Springer International Publishing},
	author = {Hasnain, Ali and Rebholz-Schuhmann, Dietrich},
	editor = {Gangemi, Aldo and Gentile, Anna Lisa and Nuzzolese, Andrea Giovanni and Rudolph, Sebastian and Maleshkova, Maria and Paulheim, Heiko and Pan, Jeff Z and Alam, Mehwish},
	year = {2018},
	doi = {10.1007/978-3-319-98192-5_60},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {469--477},
	file = {Hasnain und Rebholz-Schuhmann - 2018 - Assessing FAIR Data Principles Against the 5-Star .pdf:C\:\\Users\\ant87282\\Zotero\\storage\\CLVABJ2L\\Hasnain und Rebholz-Schuhmann - 2018 - Assessing FAIR Data Principles Against the 5-Star .pdf:application/pdf},
}

@misc{berners-lee_linked_2006,
	title = {Linked {Data}},
	url = {https://www.w3.org/DesignIssues/LinkedData.html},
	author = {Berners-Lee, Tim},
	month = jul,
	year = {2006},
	file = {Berners-Lee - 2006 - Linked Data.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\7QGSJJXE\\Berners-Lee - 2006 - Linked Data.pdf:application/pdf},
}

@misc{noauthor_pid_2024,
	title = {{PID}},
	url = {https://forschungsdaten.info/themen/veroeffentlichen-und-archivieren/persistente-identifikatoren/},
	month = mar,
	year = {2024},
}

@misc{tib_persistent_nodate,
	title = {Persistent {Identifiers} ({PIDs})},
	url = {https://projects.tib.eu/pid-service/persistent-identifiers/persistent-identifiers-pids/},
	author = {{TIB}},
}

@misc{berners-lee_universal_nodate,
	title = {Universal {Resource} {Identifiers}},
	url = {https://www.w3.org/Addressing/URL/uri-spec.html},
	author = {Berners-Lee, Tim},
}

@misc{tib_digital_nodate,
	title = {Digital {Object} {Identifier} ({DOI})},
	url = {https://projects.tib.eu/pid-service/persistent-identifiers/digital-object-identifiers-dois/},
	author = {{TIB}},
}

@misc{humboldt_universitat_zu_berlin_urn_2023,
	title = {{URN}},
	url = {https://www.ub.hu-berlin.de/de/bibliotheksglossar/urn},
	author = {{Humboldt Universität zu Berlin}},
	month = jan,
	year = {2023},
}

@misc{noauthor_orcid_nodate,
	title = {{ORCID}},
	url = {https://orcid.org/},
}

@misc{noauthor_research_nodate,
	title = {Research {Organization} {Registry}},
	url = {https://ror.org/},
}

@misc{noauthor_gemeinsame_2022,
	title = {Gemeinsame {Normdatei} ({GND})},
	url = {https://www.dnb.de/DE/Professionell/Standardisierung/GND/gnd_node.html},
	month = aug,
	year = {2022},
}

@misc{buchner_persistente_2015,
	title = {Persistente {Identifikatoren} für unterschiedliche {Ressourcen} aller {Kultursparten}},
	copyright = {Deutsche Digitale Bibliothek},
	url = {https://www.deutsche-digitale-bibliothek.de/content/blog/persistente-identifikatoren-fuer-unterschiedliche-ressourcen-aller-kultursparten},
	author = {Büchner, Michael},
	month = apr,
	year = {2015},
}

@misc{govdata_anleitung_2024,
	title = {Anleitung zur {Datenbereitstellung} auf {GovData}},
	url = {https://www.govdata.de/datenbereitstellungaufgovdata},
	author = {{GovData}},
	month = may,
	year = {2024},
}

@misc{tib_anleitungen_nodate,
	title = {Anleitungen zur {DOI}-{Registrierung}},
	url = {https://projects.tib.eu/pid-service/tib-doi-konsortium/anleitungen-zur-doi-registrierung/},
	author = {{TIB}},
}

@incollection{lindgren_linked_2019,
	address = {Cham},
	title = {Linked {Data} in the {European} {Data} {Portal}: {A} {Comprehensive} {Platform} for {Applying} {DCAT}-{AP}},
	volume = {11685},
	isbn = {978-3-030-27324-8 978-3-030-27325-5},
	shorttitle = {Linked {Data} in the {European} {Data} {Portal}},
	url = {https://link.springer.com/10.1007/978-3-030-27325-5_15},
	abstract = {Abstract
            
              The European Data Portal (EDP) is a central access point for metadata of Open Data published by public authorities in Europe and acquires data from more than 70 national data providers. The platform is a starting point in adopting the Linked Data specification DCAT-AP, aiming to increase interoperability and accessibility of Open Data. In this paper, we present the design of the central data management components of the platform, responsible for metadata storage, data harvesting and quality assessment. The core component is based on CKAN, which is extended by the support for native Linked Data replication to a triplestore to ensure legacy compatibility and the support for DCAT-AP. Regular data harvesting and the creation of detailed quality reports are performed by custom components adressing the requirements of DCAT-AP. The EDP is well on track to become the core platform for European Open Data and fostered the acceptance of DCAT-AP. Our platform is available here:
              https://www.europeandataportal.eu
              .},
	language = {en},
	urldate = {2024-04-09},
	booktitle = {Electronic {Government}},
	publisher = {Springer International Publishing},
	author = {Kirstein, Fabian and Dittwald, Benjamin and Dutkowski, Simon and Glikman, Yury and Schimmler, Sonja and Hauswirth, Manfred},
	editor = {Lindgren, Ida and Janssen, Marijn and Lee, Habin and Polini, Andrea and Rodríguez Bolívar, Manuel Pedro and Scholl, Hans Jochen and Tambouris, Efthimios},
	year = {2019},
	doi = {10.1007/978-3-030-27325-5_15},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {Data quality, Linked Data},
	pages = {192--204},
	file = {Volltext:C\:\\Users\\ant87282\\Zotero\\storage\\GDLCVBTD\\Kirstein et al. - 2019 - Linked Data in the European Data Portal A Compreh.pdf:application/pdf},
}

@article{bulazel_importance_2016,
	title = {The {Importance} of {Authoritative} {URI} {Design} {Schemes} for {Open} {Government} {Data}:},
	volume = {3},
	issn = {2334-4520, 2334-4539},
	shorttitle = {The {Importance} of {Authoritative} {URI} {Design} {Schemes} for {Open} {Government} {Data}},
	url = {https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJPADA.2016040101},
	doi = {10.4018/IJPADA.2016040101},
	abstract = {A major challenge when working with open government data is managing, connecting, and understanding the links between references to entities found across multiple datasets when these datasets use different vocabularies to refer to identical entities (i.e.: one dataset may refer to Microsoft as “Microsoft”, another may refer to the company by its SEC filing number as “0000789019”, and a third may use its stock ticker “MSFT”.) In this paper the authors propose a naming scheme based on Web URLs that enables unambiguous naming and linking of datasets and, more importantly, data elements, across the Web. They further describe their ongoing work to demonstrate the implementation and authoritative management of such schemes through a class of web service they refer to as the “instance hub”. When working with linked government data, provided either directly from governments via open government programs or through other sources, the issue of resolving inconsistencies in naming schemes is particularly important, as various agencies have disparate conventions for referring to the same concepts and entities. Using linked data technologies the authors have created instance hubs to assist in the management and linking of entity references for collections of categorically and hierarchically related entities. Instance hubs are of particular interest to governments engaged in the publication of linked open government data, as they can help data consumers make better sense of published data and can provide a starting point for development of linked data applications. In this paper the authors present their findings from the ongoing development of a prototype instance hub at the Tetherless World Constellation at Rensselaer Polytechnic Institute (TWC RPI). The TWC RPI Instance Hub enables experimentation and verification of proposed URI design schemes for open government data, especially those developed at TWC in collaboration with the United States Data.gov program. They discuss core principles of the TWC RPI Instance Hub design and implementation, and summarize how they have used their instance hub to demonstrate the possibilities for authoritative entity references across a number of heterogeneous categories commonly found in open government data, including countries, federal agencies, states, counties, crops, and toxic chemicals.},
	language = {ng},
	number = {2},
	urldate = {2024-04-09},
	journal = {International Journal of Public Administration in the Digital Age},
	author = {Bulazel, Alexei and DiFranzo, Dominic and Erickson, John S. and Hendler, James A.},
	month = apr,
	year = {2016},
	keywords = {Data quality, Linked Data},
	pages = {1--18},
}

@book{przyborski_qualitative_2014,
	address = {München},
	edition = {4., erweiterte Auflage},
	series = {Lehr- und {Handbücher} der {Soziologie}},
	title = {Qualitative {Sozialforschung}: {Ein} {Arbeitsbuch}},
	isbn = {978-3-486-70892-9},
	shorttitle = {Qualitative {Sozialforschung}},
	language = {de},
	publisher = {Oldenbourg Verlag},
	author = {Przyborski, Aglaja and Wohlrab-Sahr, Monika},
	year = {2014},
	keywords = {Datenqualität, Empirische Sozialdaten},
	file = {Przyborski and Wohlrab-Sahr - 2014 - Qualitative Sozialforschung Ein Arbeitsbuch.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\2SLNSYKR\\Przyborski and Wohlrab-Sahr - 2014 - Qualitative Sozialforschung Ein Arbeitsbuch.pdf:application/pdf},
}

@book{hader_empirische_2019,
	address = {Wiesbaden},
	title = {Empirische {Sozialforschung}: {Eine} {Einführung}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-658-26985-2 978-3-658-26986-9},
	shorttitle = {Empirische {Sozialforschung}},
	url = {http://link.springer.com/10.1007/978-3-658-26986-9},
	language = {de},
	urldate = {2024-04-24},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Häder, Michael},
	year = {2019},
	doi = {10.1007/978-3-658-26986-9},
	keywords = {Datenqualität, Empirische Sozialdaten},
	file = {Häder - 2019 - Empirische Sozialforschung Eine Einführung.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\38962SL4\\Häder - 2019 - Empirische Sozialforschung Eine Einführung.pdf:application/pdf},
}

@article{saidani_qualitatsdimensionen_2023,
	title = {Qualitätsdimensionen maschinellen {Lernens} in der amtlichen {Statistik}},
	volume = {17},
	issn = {1863-8163},
	url = {https://doi.org/10.1007/s11943-023-00329-7},
	doi = {10.1007/s11943-023-00329-7},
	abstract = {Die amtliche Statistik zeichnet sich durch ihren gesetzlich auferlegten Fokus auf die Qualität ihrer Veröffentlichungen aus. Dabei folgt sie den europäischen Qualitätsrahmenwerken, die auf nationaler Ebene in Form von Qualitätshandbüchern konkretisiert und operationalisiert werden, sich jedoch bis dato hinsichtlich Ausgestaltung und Interpretation an den Anforderungen der „klassischen“ Statistikproduktion orientieren. Der zunehmende Einsatz maschineller Lernverfahren (ML) in der amtlichen Statistik muss daher zur Erfüllung des Qualitätsanspruchs durch ein spezifisches, darauf zugeschnittenes Qualitätsrahmenwerk begleitet werden. Das vorliegende Papier leistet einen Beitrag zur Erarbeitung eines solchen Qualitätsrahmenwerks für den Einsatz von ML in der amtlichen Statistik, indem es (1) durch den Vergleich mit bestehenden Qualitätsgrundsätzen des Verhaltenskodex für Europäische Statistiken relevante Qualitätsdimensionen für ML identifiziert und (2) diese unter Berücksichtigung der besonderen methodischen Gegebenheiten von ML ausarbeitet. Dabei (2a) ergänzt es bestehende Vorschläge durch den Aspekt der Robustheit, (2b) stellt Bezug zu den Querschnittsthemen Machine Learning Operations (MLOps) und Fairness her und (2c) schlägt vor, wie die Qualitätssicherung der einzelnen Dimensionen in der Praxis der amtlichen Statistik ausgestaltet werden kann. Diese Arbeit liefert die konzeptionelle Grundlage, um Qualitätsindikatoren für ML-Verfahren formell in die Instrumente des Qualitätsmanagements im Statistischen Verbund zu überführen und damit langfristig den hohen Qualitätsstandard amtlicher Statistik auch bei Nutzung neuer Verfahren zu sichern.},
	language = {de},
	number = {3},
	urldate = {2024-04-24},
	journal = {AStA Wirtschafts- und Sozialstatistisches Archiv},
	author = {Saidani, Younes and Dumpert, Florian and Borgs, Christian and Brand, Alexander and Nickl, Andreas and Rittmann, Alexandra and Rohde, Johannes and Salwiczek, Christian and Storfinger, Nina and Straub, Selina},
	month = dec,
	year = {2023},
	pages = {253--303},
	file = {Full Text PDF:C\:\\Users\\ant87282\\Zotero\\storage\\6XLJRXEW\\Saidani et al. - 2023 - Qualitätsdimensionen maschinellen Lernens in der a.pdf:application/pdf},
}

@incollection{zehnder_datenmanipulation_1987,
	address = {Wiesbaden},
	title = {Datenmanipulation},
	isbn = {978-3-322-94122-0},
	url = {https://doi.org/10.1007/978-3-322-94122-0_4},
	abstract = {In einer Datenbank gespeicherte Daten haben für den Benutzer erst dann einen Sinn, wenn sie wieder abgefragt oder in anderer Weise benützt und bearbeitet, allgemein gesagt manipuliert werden können. Schon in der Übersicht (Unterabschnitt 1.5.3) haben wir dabei Abfragen und Mutationen unterschieden.— Abfragen bilden die häufigste Art, Daten zu manipulieren. Es stellt sich in diesem Zusammenhang das bei einer Datenbank nicht-triviale Problem der geeigneten Auswahl einer Teilmenge des Datenbestandes. In Kapitel 4 kommen die logischen Aspekte dieses Auswahlverfahrens zur Sprache, in Abschnitt 5.4 die physischen Zugriffspfade.— Auch bei Mutationen ist der Prozess der Datenauswahl von Bedeutung, da dem System mitgeteilt werden muss, welche Teilmenge der Daten verändert werden soil. Dazu kommen aber noch vielschichtige Probleme der Datenintegrität, denn bei jeder einzelnen Mutation muss man sicherstellen, dass der Inhalt der Datenbank konsistent bleibt. Ihrer Bedeutung wegen werden die Aspekte der Datenintegrität in Kapitel 6 zusammenfassend behandelt.},
	language = {de},
	urldate = {2024-04-26},
	booktitle = {Informationssysteme und {Datenbanken}},
	publisher = {Vieweg+Teubner Verlag},
	author = {Zehnder, Carl August},
	year = {1987},
	doi = {10.1007/978-3-322-94122-0_4},
	keywords = {Datenmanipulation},
	pages = {110--159},
	file = {Zehnder - 1987 - Datenmanipulation.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\V9BYIR46\\Zehnder - 1987 - Datenmanipulation.pdf:application/pdf},
}

@article{wickham_tidy_2014,
	title = {Tidy {Data}},
	volume = {59},
	copyright = {Copyright (c) 2013 Hadley  Wickham},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v059.i10},
	doi = {10.18637/jss.v059.i10},
	abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
	language = {en},
	urldate = {2024-04-26},
	journal = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	month = sep,
	year = {2014},
	keywords = {Datenmanipulation},
	pages = {1--23},
	file = {Wickham - 2014 - Tidy Data.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\XGLMIIUT\\Wickham - 2014 - Tidy Data.pdf:application/pdf},
}


@article{syrian_virtual_university_damascus_syria_linked_2021,
	title = {Linked {Data}: {A} {Framework} for {Publishing} {FiveStar} {Open} {Government} {Data}},
	volume = {13},
	issn = {20749007, 20749015},
	shorttitle = {Linked {Data}},
	url = {https://www.mecs-press.org/ijitcs/ijitcs-v13-n6/v13n6-1.html},
	doi = {10.5815/ijitcs.2021.06.01},
	abstract = {With the increased adoption of open government initiatives around the world, a huge amount of governmental raw datasets was released. However, the data was published in heterogeneous formats and vocabularies and in many cases in bad quality due to inconsistency, messy, and maybe incorrectness as it has been collected by practicalities within the source organization, which makes it inefficient for reusing and integrating it for serving citizens and third-party apps.},
	language = {en},
	number = {6},
	urldate = {2024-06-01},
	journal = {International Journal of Information Technology and Computer Science},
	author = {{Syrian Virtual University, Damascus, Syria} and Al-khatib, Bassel and Ali, Ali Ahmad},
	month = dec,
	year = {2021},
	pages = {1--15},
	file = {Syrian Virtual University, Damascus, Syria et al. - 2021 - Linked Data A Framework for Publishing FiveStar O.pdf:C\:\\Users\\ant87282\\Zotero\\storage\\XLRU3PMC\\Syrian Virtual University, Damascus, Syria et al. - 2021 - Linked Data A Framework for Publishing FiveStar O.pdf:application/pdf},
}

@incollection{heilsberger_empirische_2023,
	title = {Empirische {Verwaltungswissenschaft}},
	isbn = {978-3-658-39803-3},
	url = {https://doi.org/10.1007/978-3-658-39803-3},
	booktitle = {Empirische {Sozialforschung} für die {Polizei}- und {Verwaltungswissenschaften}},
	publisher = {Springer VS},
	author = {Heilsberger, Lars and Seyfried, Markus},
	year = {2023},
}

@misc{dfg_leitlinien_2022,
	title = {Leitlinien zur {Sicherung} guter wissenschaftlicher {Praxis}},
	url = {https://www.dfg.de/resource/blob/173732/4166759430af8dc2256f0fa54e009f03/kodex-gwp-data.pdf},
	author = {{DFG}},
	month = apr,
	year = {2022},
}

@misc{bundesdruckerei_was_2023,
	title = {Was sind {FAIR} {Digital} {Objects}?},
	url = {https://www.bundesdruckerei.de/de/innovation-hub/was-sind-fair-digital-objects},
	author = {{Bundesdruckerei}},
	month = jan,
	year = {2023},
}

@book{noauthor_reproducibility_2019,
	title = {Reproducibility and {Replicability} in {Science}},
	isbn = {978-0-309-48619-4},
	abstract = {One of the pathways by which the scientific community confirms the validity of a new scientific discovery is by repeating the research that produced it. When a scientific effort fails to independently confirm the computations or results of a previous study, some fear that it may be a symptom of a lack of rigor in science, while others argue that such an observed inconsistency can be an important precursor to new discovery. Concerns about reproducibility and replicability have been expressed in both scientific and popular media. As these concerns came to light, Congress requested that the National Academies of Sciences, Engineering, and Medicine conduct a study to assess the extent of issues related to reproducibility and replicability and to offer recommendations for improving rigor and transparency in scientific research. Reproducibility and Replicability in Science defines reproducibility and replicability and examines the factors that may lead to non-reproducibility and non-replicability in research. Unlike the typical expectation of reproducibility between two computations, expectations about replicability are more nuanced, and in some cases a lack of replicability can aid the process of scientific discovery. This report provides recommendations to researchers, academic institutions, journals, and funders on steps they can take to improve reproducibility and replicability in science.},
	language = {en},
	publisher = {National Academies Press},
	author = {National Academies of Sciences, Engineering and Medicine},
	month = sep,
	year = {2019},
}

@misc{noauthor_persistente_2024,
	title = {Persistente {Identifikatoren}},
	urldate = {2024-06-06},
	journal = {Persistente Identifikatoren},
	month = mar,
	year = {2024},
}

@book{groves_federal_2017,
	address = {Washington, D.C.},
	title = {Federal {Statistics}, {Multiple} {Data} {Sources}, and {Privacy} {Protection}: {Next} {Steps}},
	isbn = {978-0-309-46537-3},
	shorttitle = {Federal {Statistics}, {Multiple} {Data} {Sources}, and {Privacy} {Protection}},
	url = {https://www.nap.edu/catalog/24893},
	urldate = {2024-04-30},
	publisher = {National Academies Press},
	editor = {Groves, Robert M. and Harris-Kojetin, Brian A.},
	collaborator = {{Panel on Improving Federal Statistics for Policy and Social Science Research Using Multiple Data Sources and State-of-the-Art Estimation Methods} and {Committee on National Statistics} and {Division of Behavioral and Social Sciences and Education} and {National Academies of Sciences, Engineering, and Medicine}},
	month = dec,
	year = {2017},
	doi = {10.17226/24893},
	keywords = {Datenqualität, Qualitiy Framework},
	file = {Full Text:C\:\\Users\\ant87282\\Zotero\\storage\\6BI8SV4D\\Groves and Harris-Kojetin - 2017 - Federal Statistics, Multiple Data Sources, and Pri.pdf:application/pdf},
}

@misc{lang_what_2023,
	title = {What is the {Normalization} of databases?},
	shorttitle = {What is the {Normalization} of databases?},
	url = {https://databasecamp.de/en/data/normalization},
	language = {en-US},
	urldate = {2024-06-24},
	author = {Lang, Niklas},
	month = may,
	year = {2023},
}

@misc{jones_how_2017,
  author       = {Jones, Sarah and
                  Grootveld, Marjan},
  title        = {How FAIR are your data?},
  month        = nov,
  year         = 2017,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.5111307},
  url          = {https://doi.org/10.5281/zenodo.5111307}
}

@article{broman_data_2018,
    title = {Data Organization in Spreadsheets},
    volume = {72},
    issn = {0003-1305},
    url = {https://doi.org/10.1080/00031305.2017.1375989},
    doi = {10.1080/00031305.2017.1375989},
    number = {1},
    journal = {The American Statistician},
    author = {Broman, Karl W. and Woo, Kara H.},
    year = {2018},
    pages = {2--10}
}

@article{Codd_1971,
  title={Further Normalization of the Data Base Relational Model},
  author={E. F. Codd},
  journal={Research Report / RJ / IBM / San Jose, California},
  year={1971},
  volume={RJ909},
  url={https://api.semanticscholar.org/CorpusID:45071523}
}

@article{khodorovskii_normalization_2002,
	title = {On Normalization of Relations in Relational Databases},
	volume = {28},
	issn = {1608-3261},
	url = {https://doi.org/10.1023/A:1013759617481},
	doi = {10.1023/A:1013759617481},
	number = {1},
	journal = {Programming and Computer Software},
	author = {Khodorovskii, V. V.},
	year = {2002},
	pages = {41--52}
}
